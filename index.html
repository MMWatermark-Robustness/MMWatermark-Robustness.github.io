<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="MultiSum: A Dataset for Multimodal Summarization and Thumbnail Generation of Videos">
    <meta name="author"
          content="Jielin Qiu, Jiacheng Zhu, William Han, Aditesh Kumar, Karthik Mittal, Claire Jin, Zhengyuan Yang, Linjie Li, Jianfeng Wang, Bo Li, Ding Zhao, Lijuan Wang">

    <title>MultiSum: A Dataset for Multimodal Summarization and Thumbnail Generation of Videos</title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
    <!--    <link rel="icon" href="img/favicon.gif" type="image/gif">-->
</head>

<body>
<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
    <h2>MultiSum: A Dataset for Multimodal Summarization and Thumbnail Generation of Videos</h2>
    <hr>
    <p class="authors">
        <a href="https://www.cs.cmu.edu/~jielinq/">Jielin Qiu<sup>1,2</sup></a>,
        <a href="https://jiachengzhuml.github.io/">Jiacheng Zhu<sup>1</sup></a>,
        <a href="https://willxxy.github.io/">William Han<sup>1</sup></a>,
        <a href="">Aditesh Kumar<sup>1</sup></a>,
        <a href="">Karthik Mittal<sup>1</sup></a>,
        <a href="">Claire Jin<sup>1</sup></a>,
    </p>
    <p class="authors">
        <a href="https://zyang-ur.github.io/">Zhengyuan Yang<sup>2</sup></a>,
        <a href="https://scholar.google.com/citations?user=WR875gYAAAAJ&hl=en">Linjie Li<sup>2</sup></a>,
        <a href="https://scholar.google.com/citations?user=vJWEw_8AAAAJ&hl=en">Jianfeng Wang<sup>2</sup></a>,
        <a href="https://safeai-lab.github.io/">Ding Zhao<sup>1</sup></a>,
        <a href="https://aisecure.github.io/">Bo Li<sup>3</sup></a>,
        <a href="https://scholar.google.com/citations?user=cDcWXuIAAAAJ&hl=en">Lijuan Wang<sup>2</sup></a>
    </p>
    <p class="authors">
        <sup>1</sup>Carnegie Mellon University,
        <sup>2</sup>Microsoft Azure AI,
        <sup>3</sup>University of Chicago
    </p>
    <div class="btn-group" role="group" aria-label="Top menu">
        <a class="btn btn-primary" href="https://drive.google.com/drive/folders/1ZE3p7JmoZe0EK-HIxpKrYUdHqXwFabUf?usp=sharing">Dataset</a>
    </div>
    <div class="btn-group" role="group" aria-label="Top menu">
        <a class="btn btn-primary" href="https://arxiv.org/abs/2306.04216">Paper</a>
    </div>
    <div class="btn-group" role="group" aria-label="Top menu">
        <a class="btn btn-primary" href="https://github.com/Jason-Qiu/MultiSum_Data_Collection_Tool">Data Collection Tool</a>
    </div>
    <div class="btn-group" role="group" aria-label="Top menu">
        <a class="btn btn-primary" href="https://github.com/Jason-Qiu/MultiSum_model">Model Code</a>
    </div>
</div>

<div class="container">
    <div class="section">
        <div class="col justify-content-center text-center">
            <div class="col-sm-12">
                <img src="images/multisum_categories.png" style="width:80%">
            </div>
        </div>
        <p>
         The 17 main categories of the MultiSum dataset, where each main category contains 10 subcategories, resulting in 170 subcategories in total.
        </p>
    </div>

    <div class="section">
        <h2>Abstract</h2>
        <hr>
        <p>
            Multimodal summarization with multimodal output (MSMO) has emerged as a promising research direction.
            Nonetheless, numerous limitations exist within existing public MSMO datasets, including insufficient upkeep, data inaccessibility, limited size, and the absence of proper categorization, which pose significant challenges to effective research.
            To address these challenges and provide a comprehensive dataset for this new direction, we have meticulously curated the MultiSum dataset.
            Our new dataset features
            (1) Human-validated summaries for both video and textual content, providing superior human instruction and labels for multimodal learning.
            (2) Comprehensively and meticulously arranged categorization, spanning 17 principal categories and 170 subcategories to encapsulate a diverse array of real-world scenarios.
            (3) Benchmark tests performed on the proposed dataset to assess varied tasks and methods, including video temporal segmentation, video summarization, text summarization, and multimodal summarization.
            To champion accessibility and collaboration, we release the MultiSum dataset and the data collection tool as fully open-source resources, fostering transparency and accelerating future developments.
        </p>
    </div>

    <br>


    <div class="section">
        <h2>MultiSum Data Statistics</h2>
        <hr>
        <div class="col justify-content-center text-center">
            <div class="col-sm-12">
                <img src="images/multisum_statistics.png" style="width:100%">
            </div>
        </div>
        <p>
            The statistics of the MultiSum dataset, which show the distribution of (a) video duration; (b) number of segments per video; (c) segment duration; (d) number of words per sentence.
        </p>
    </div>

    <br>



    <div class="section">
        <h2>Task Comparison</h2>
        <hr>
        <div class="col justify-content-center text-center">
            <div class="col-sm-12">
                <img src="images/task_compare.png" style="width:100%">
            </div>
        </div>
        <p>
            Task comparison of traditional video summarization, text summarization, and the new MSMO (multimodal summarization with multimodal output) task.
        </p>

        <div class="col justify-content-center text-center">
            <div class="col-sm-12">
                <img src="images/dataset_comparison.png" style="width:100%">
            </div>
        </div>
        <p>
            Comparison with existing video summarization and multimodal summarization datasets.
        </p>
    </div>

    <br>



    <div class="section">
        <h2>MultiSum Benchmark Pipeline</h2>

        <hr>
        <div class="col justify-content-center text-center">
            <div class="col-sm-12">
                <img src="images/pipeline.png" style="width:100%">
            </div>
        </div>
        <p>
            The design of the proposed MultiSum dataset is driven by research and application needs.
        </p>
    </div>

    <br>

    <div class="section">
        <h2>Comparison of different summarization tasks and datasets</h2>
        <hr>
        <div class="col justify-content-center text-center">
            <div class="col-sm-12">
                <img src="images/comparison_table.png" style="width:100%">
            </div>
        </div>
        <p>
            Comparison of the modality of different summarization tasks and datasets, where MSMO is short for Multimodal Summarization with Multimodal Output. The major difference between traditional multimodal summarization and MSMO is that traditional multimodal summarization still outputs a single-modality summary, while MSMO outputs both modalities' summaries.
        </p>

    </div>

    <div class="section">
        <h2>Thumbnail Generation</h2>
        <hr>
        <div class="col justify-content-center text-center">
            <div class="col-sm-12">
                <img src="images/thumbnail_v1.png" style="width:100%">
            </div>
        </div>
        <p>
            One direct and practical application of the MSMO task is to automatically generate thumbnails for a given video, which has become increasingly valuable in various real-world applications. With the exponential growth of online videos, effective and efficient methods are required to extract visually appealing and informative thumbnail representations.
In addition, many author-generated thumbnails involve words or titles that describe the whole video to attract more users.
In the context of online platforms, such as video-sharing websites or social media platforms, compelling thumbnails can significantly impact user engagement, content discoverability, and overall user experience. The benefits of automated thumbnail generation extend beyond user engagement and content discoverability. In e-commerce, for instance, thumbnails can play a vital role in attracting potential buyers by effectively showcasing products or services. Similarly, in video editing workflows, quick and accurate thumbnail generation can aid content creators in managing and organizing large video libraries efficiently.
        </p>

    </div>

    <br>

    <div class="section">
        <h2>Bibtex</h2>
        <hr>
        <div class="crop"></div>
        <div class="bibtexsection">
    @inproceedings{Qiu2023MMSumAD,
        title={MultiSum: A Dataset for Multimodal Summarization and Thumbnail Generation of Videos},
        author={Jielin Qiu and Jiacheng Zhu and William Han and Aditesh Kumar and Karthik Mittal
                and Claire Jin and Zhengyuan Yang and Linjie Li and Jianfeng Wang
                and Bo Li and Ding Zhao and Lijuan Wang},
        journal={CVPR},
        year={2024}
        </div>
        </div>
    </div>

    <br>


    <hr>

    <footer>
        <p>
            Acknowledgement: This page is modified from <a href="https://yilundu.github.io/">Yilun Du</a>.
        </p>
    </footer>






</div>


<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

</body>
</html>
